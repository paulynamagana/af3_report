{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZ5F5ieydbI+wTRUm2XWq4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paulynamagana/af3_report/blob/main/AFserver_report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AlphaFold Results Visualisation\n",
        "\n",
        "This Google Colab provides tools to streamline the analysis and visualization of protein structure predictions generated by AlphaFold Server. It allows you to:\n",
        "\n",
        "Easily update your AlphaFold zip files.\n",
        "Generate insightful plots from the prediction results, including:\n",
        "* Predicted Aligned Error (PAE)\n",
        "* Predicted Local Distance Difference Test (pLDDT)\n",
        "* Inter-chain Predicted TM-score (ipTM)\n",
        "* Predicted TM-score (pTM)\n",
        "* Contact Probabilities"
      ],
      "metadata": {
        "id": "hXoce4cHXqQR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to Use This Colab\n",
        "\n",
        "1. Upload your AlphaFold zip file.\n",
        "2. Run the provided code to extract the data and generate the plots.\n",
        "3. Analyze the plots and data to gain insights into your protein structure prediction.\n",
        "\n",
        "* Note: These metrics are based on AlphaFold's internal representations (\"tokens\"), which encompass standard amino acids, small molecules, and chemically modified residues."
      ],
      "metadata": {
        "id": "xzsojCAD8Vm1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "cellView": "form",
        "id": "zRWQzbVSHSJR",
        "outputId": "eba858d3-ef6a-486a-bdea-e653261a368c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: reportlab in /usr/local/lib/python3.10/dist-packages (4.2.5)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from reportlab) (11.0.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from reportlab) (5.2.0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9c6d9873-7ed5-4db7-a1fe-1c2eca782950\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9c6d9873-7ed5-4db7-a1fe-1c2eca782950\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving fold_protein_dna_kat6a.zip to fold_protein_dna_kat6a.zip\n"
          ]
        }
      ],
      "source": [
        "#@markdown Run this cell to upload the zip file generated from the AlphaFold Server\n",
        "\n",
        "#@markdown **Note**: At the bottom of this code you will see an option to upload a file, select the .zip file from the AlphaFold Server. The upload  might take a couple of minutes.\n",
        "\n",
        "!pip install reportlab\n",
        "import zipfile\n",
        "import os\n",
        "from google.colab import files\n",
        "import shutil\n",
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "from pathlib import Path\n",
        "import glob\n",
        "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
        "import seaborn as sns\n",
        "from matplotlib.patches import Rectangle\n",
        "from matplotlib.cm import get_cmap\n",
        "from matplotlib.lines import Line2D\n",
        "from matplotlib.gridspec import GridSpec\n",
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.pdfgen import canvas\n",
        "import string\n",
        "from matplotlib.table import Table\n",
        "from matplotlib import colormaps\n",
        "\n",
        "\n",
        "#current directory\n",
        "current_dir = '/content/'\n",
        "\n",
        "# Loop through the files and delete them\n",
        "for filename in os.listdir(current_dir):\n",
        "    file_path = os.path.join(current_dir, filename)\n",
        "    if os.path.isfile(file_path):\n",
        "        os.remove(file_path)\n",
        "    elif os.path.isdir(file_path):\n",
        "        shutil.rmtree(file_path)\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "filename = list(uploaded.keys())[0]\n",
        "\n",
        "with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "       zip_ref.extractall('unzipped_files')\n",
        "\n",
        "#create folder for outputs\n",
        "output_dir = \"/content/outputs\"\n",
        "Path(output_dir).mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown  Run this cell to get PAE, pLDDT and contact probability plots\n",
        "\n",
        "#@markdown Combined Plots (combined.png): These plots provide a more detailed view of the prediction quality and residue-level contacts.\n",
        "\n",
        "#@markdown * pae: Visualizes the expected error in the predicted position of each residue relative to others.\n",
        "#@markdown * atom_plddts: Indicates the confidence in the predicted local structure around each atom. Higher pLDDT values suggest higher accuracy.\n",
        "#@markdown * contact_probs: Shows the probability of contact between pairs of residues.\n",
        "\n",
        "def load_data_from_json(json_path):\n",
        "    try:\n",
        "        with open(json_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        pae_matrix = np.array(data.get(\"pae\", []))\n",
        "        plddt_scores = data.get(\"atom_plddts\", [])\n",
        "        token_chain_ids = data.get(\"token_chain_ids\", [])\n",
        "        token_res_ids = data.get(\"token_res_ids\", [])\n",
        "        contact_proba_data = np.array(data.get(\"contact_probs\", []))\n",
        "\n",
        "        if pae_matrix.size == 0 or not plddt_scores:\n",
        "            raise ValueError(\"Missing required keys ('pae', 'plddt') in JSON file.\")\n",
        "\n",
        "        return pae_matrix, plddt_scores, token_chain_ids, token_res_ids, contact_proba_data\n",
        "    except (FileNotFoundError, json.JSONDecodeError, KeyError, ValueError) as e:\n",
        "        print(f\"Error loading JSON file: {e}\")\n",
        "        return None, None, None, None, None, None\n",
        "\n",
        "\n",
        "##function to plot any matrix\n",
        "def plot_matrix(matrix, type_matrix, ax=None):\n",
        "    \"\"\"\n",
        "    Plot the PAE matrix on the given axis.\n",
        "\n",
        "    Parameters:\n",
        "    - pae_matrix: 2D NumPy array of PAE values.\n",
        "    - ax: Matplotlib axis object, optional. If None, a new axis is created.\n",
        "\n",
        "    Returns:\n",
        "    - ax: Matplotlib axis object with the plot.\n",
        "    \"\"\"\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots(figsize=(12, 12))\n",
        "    if type_matrix == \"PAE\":\n",
        "        ax.set_facecolor(\"white\")\n",
        "        cmap = ax.imshow(\n",
        "            matrix,\n",
        "            vmin=0,\n",
        "            vmax=32,\n",
        "            cmap=\"Greens_r\"\n",
        "        )\n",
        "        ax.set_xlabel(\"Scored Residue\")\n",
        "        ax.set_ylabel(\"Aligned Residue\")\n",
        "        return ax, cmap\n",
        "    if type_matrix == \"contact\":\n",
        "        cmap = ax.imshow(\n",
        "            matrix,\n",
        "            vmin=0,\n",
        "            vmax=1,\n",
        "            cmap=\"viridis\"\n",
        "        )\n",
        "        ax.set_xlabel(\"Residue i\")\n",
        "        ax.set_ylabel(\"Residue j\")\n",
        "        return ax, cmap\n",
        "\n",
        "##this is to add chain boundaries to the axis\n",
        "def add_chain_boundaries(token_chain_ids, token_res_ids, ax):\n",
        "    \"\"\"\n",
        "    Add chain boundaries and labels using token_chain_ids and token_res_ids.\n",
        "\n",
        "    Parameters:\n",
        "    - token_chain_ids: list of chain IDs for each token.\n",
        "    - token_res_ids: list of residue numbers for each token.\n",
        "    - ax: Matplotlib axis object.\n",
        "    \"\"\"\n",
        "    chain_ranges = []\n",
        "    current_chain = None\n",
        "    start = 0\n",
        "\n",
        "    for i, (chain_id, res_id) in enumerate(zip(token_chain_ids, token_res_ids)):\n",
        "        if current_chain is None:\n",
        "            current_chain = chain_id\n",
        "\n",
        "        if chain_id != current_chain or i == len(token_chain_ids) - 1:\n",
        "            end = i - 1 if i == len(token_chain_ids) - 1 else i\n",
        "            chain_ranges.append((current_chain, start, end))\n",
        "            current_chain = chain_id\n",
        "            start = i\n",
        "\n",
        "\n",
        "    # to define a color palette with enough colors for all chains\n",
        "    num_chains = len(chain_ranges)\n",
        "\n",
        "    # get a colormap with enough colors\n",
        "    if num_chains <= 10:\n",
        "        color_palette = colormaps[\"tab10\"]\n",
        "    elif num_chains <= 20:\n",
        "        color_palette = colormaps[\"tab20\"]\n",
        "    else:\n",
        "        color_palette = colormaps[\"tab20c\"]\n",
        "\n",
        "    # generate colors for each chain\n",
        "    colors = [color_palette(i / num_chains) for i in range(num_chains)]\n",
        "    # custom legend entries\n",
        "    legend_elements = []\n",
        "\n",
        "    for idx, (chain_id, start, end) in enumerate(chain_ranges):\n",
        "        ax.axhline(y=start, color=\"black\", linestyle=\"--\", linewidth=1)\n",
        "        ax.axvline(x=start, color=\"black\", linestyle=\"--\", linewidth=1)\n",
        "        ax.axhline(y=end, color=\"black\", linestyle=\"--\", linewidth=1)\n",
        "        ax.axvline(x=end, color=\"black\", linestyle=\"--\", linewidth=1)\n",
        "\n",
        "        # calculate mid position\n",
        "        mid_pos = (start + end) / 2\n",
        "        ax.text(mid_pos, -40, chain_id, ha=\"center\", fontsize=10, color=\"black\")\n",
        "\n",
        "        # Select a color for the chain\n",
        "        color = color_palette(idx % color_palette.N)  # Handle more chains than available colors\n",
        "        # draw the chain bottom border with the selected color\n",
        "        ax.plot([start, end], [-20, -20], color=color, linewidth=2)\n",
        "\n",
        "        # Create legend entry for this chain\n",
        "        legend_elements.append(Line2D([0], [0], color=color, lw=2, label=f\"Chain {chain_id}\"))\n",
        "\n",
        "        ax.text(-45, mid_pos, chain_id, ha=\"center\", fontsize=10, color=\"black\", rotation=90)\n",
        "        ax.plot([-15, -15], [start, end], color=color, linewidth=2)\n",
        "        ax.tick_params(axis='both', which='major', pad=10)\n",
        "\n",
        "##combine all plots in one png\n",
        "def plot_combined(pae_matrix, plddt_scores, token_chain_ids, token_res_ids, output_dir, json_file_name, contact_proba_data):\n",
        "    \"\"\"\n",
        "    Plot combined pLDDT, PAE, and Contact Probability in a single figure and save as a PNG file.\n",
        "\n",
        "    Parameters:\n",
        "    - pae_matrix: 2D NumPy array of PAE values.\n",
        "    - plddt_scores: list of pLDDT scores.\n",
        "    - token_chain_ids: list of chain IDs for each token.\n",
        "    - token_res_ids: list of residue IDs for each token.\n",
        "    - output_dir: str, directory to save the plot.\n",
        "    - json_file_name: str, base name of the plot file.\n",
        "    - contact_proba_data: 2D NumPy array of contact probability values.\n",
        "    \"\"\"\n",
        "    fig = plt.figure(figsize=(20, 16))\n",
        "    gs = fig.add_gridspec(2, 2, height_ratios=[0.4, 1], width_ratios=[1, 1])\n",
        "\n",
        "    # Plot pLDDT\n",
        "    ax1 = fig.add_subplot(gs[0, :])\n",
        "    total_residues = len(plddt_scores)\n",
        "    ax1.add_patch(Rectangle((0, 90), total_residues, 10, color=\"#024fcc\", alpha=0.3, label=\"Very high (pLDDT > 90)\"))\n",
        "    ax1.add_patch(Rectangle((0, 70), total_residues, 20, color=\"#60c2e8\", alpha=0.3, label=\"High (90 > pLDDT > 70)\"))\n",
        "    ax1.add_patch(Rectangle((0, 50), total_residues, 20, color=\"#f37842\", alpha=0.3, label=\"Low (70 > pLDDT > 50)\"))\n",
        "    ax1.add_patch(Rectangle((0, 0), total_residues, 50, color=\"#f9d613\", alpha=0.3, label=\"Very low (pLDDT < 50)\"))\n",
        "    sns.lineplot(x=np.arange(1, total_residues + 1), y=plddt_scores, ax=ax1, color=\"black\", linewidth=0.3)\n",
        "    ax1.set_xlabel(\"Residue\")\n",
        "    ax1.set_ylabel(\"pLDDT Score\")\n",
        "    ax1.set_ylim(0, 100)\n",
        "    ax1.set_title(\"Predicted Local Distance Difference Test (pLDDT) Scores\")\n",
        "    ax1.legend(title=\"pLDDT confidence\", loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
        "    ax1.spines[[\"right\", \"top\"]].set_visible(False)\n",
        "    ax1.set_xlim(0, total_residues + 1)  # make sure x-axis matches residue range\n",
        "    ax1.margins(0)  # disabling any additional margins\n",
        "\n",
        "    # Plot PAE\n",
        "    ax2 = fig.add_subplot(gs[1, 0])\n",
        "    ax2, cmap = plot_matrix(pae_matrix, \"PAE\", ax2)\n",
        "    add_chain_boundaries(token_chain_ids, token_res_ids, ax2)\n",
        "    fig.colorbar(cmap, ax=ax2, orientation=\"vertical\", label=\"Predicted Aligned Error (Å)\", shrink=0.5)\n",
        "    ax2.set_title(\"Predicted Aligned Error (PAE)\", pad=20)\n",
        "\n",
        "    # Plot Contact Probability Matrix\n",
        "    ax3 = fig.add_subplot(gs[1, 1])\n",
        "    ax3, cmap = plot_matrix(contact_proba_data, \"contact\", ax3)\n",
        "    add_chain_boundaries(token_chain_ids, token_res_ids, ax3)\n",
        "    fig.colorbar(cmap, ax=ax3, orientation=\"vertical\", label=\"Predicted contact\", shrink=0.5)\n",
        "    ax3.set_title(\"Contact Probability Matrix\")\n",
        "    ax3.set_xlabel(\"Residue i\")\n",
        "    ax3.set_ylabel(\"Residue j\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save plot\n",
        "    output_file = Path(output_dir) / f\"{json_file_name}_combined.png\"\n",
        "    plt.savefig(output_file, dpi=300, bbox_inches=\"tight\")\n",
        "    plt.close()\n",
        "    print(f\"Combined plot saved to {output_file}\")\n",
        "\n",
        "\n",
        "\n",
        "def process_folder(folder_path, output_dir):\n",
        "    \"\"\"\n",
        "    Process all JSON files in the folder matching the pattern *full_data_*.json.\n",
        "\n",
        "    Parameters:\n",
        "    - folder_path: str, path to the folder containing JSON files.\n",
        "    - output_dir: str, path to save the plots.\n",
        "    \"\"\"\n",
        "    json_files = glob.glob(f\"{folder_path}/*full_data_*.json\")\n",
        "    if not json_files:\n",
        "        print(f\"No matching JSON files found in folder: {folder_path}\")\n",
        "        return\n",
        "\n",
        "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    for json_file in json_files:\n",
        "        print(f\"Processing file: {json_file}\")\n",
        "        pae_matrix, plddt_scores, token_chain_ids, token_res_ids, contact_proba_data = load_data_from_json(json_file)\n",
        "        if pae_matrix is not None:\n",
        "            json_file_name = Path(json_file).stem\n",
        "            plot_combined(pae_matrix, plddt_scores, token_chain_ids, token_res_ids, output_dir, json_file_name, contact_proba_data)\n",
        "\n",
        "# wrap\n",
        "def main():\n",
        "    folder_path = \"/content/unzipped_files\"  # Modify this path to your folder\n",
        "    output_dir = \"outputs\"  # Folder to store the plots\n",
        "    process_folder(folder_path, output_dir)\n",
        "\n",
        "# Run\n",
        "main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "d-jCK3MwJPzw",
        "outputId": "7b0c28b6-fc57-48fe-d9fe-3ac688a36250"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file: /content/unzipped_files/fold_protein_dna_kat6a_full_data_1.json\n",
            "Combined plot saved to outputs/fold_protein_dna_kat6a_full_data_1_combined.png\n",
            "Processing file: /content/unzipped_files/fold_protein_dna_kat6a_full_data_2.json\n",
            "Combined plot saved to outputs/fold_protein_dna_kat6a_full_data_2_combined.png\n",
            "Processing file: /content/unzipped_files/fold_protein_dna_kat6a_full_data_4.json\n",
            "Combined plot saved to outputs/fold_protein_dna_kat6a_full_data_4_combined.png\n",
            "Processing file: /content/unzipped_files/fold_protein_dna_kat6a_full_data_0.json\n",
            "Combined plot saved to outputs/fold_protein_dna_kat6a_full_data_0_combined.png\n",
            "Processing file: /content/unzipped_files/fold_protein_dna_kat6a_full_data_3.json\n",
            "Combined plot saved to outputs/fold_protein_dna_kat6a_full_data_3_combined.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown  Run this cell to generate overall iptms and ptm for all 5 predicted models\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def load_data_from_json(json_path):\n",
        "    \"\"\"\n",
        "    Load chain iptm data and other metrics from a JSON file.\n",
        "\n",
        "    Parameters:\n",
        "    - json_path: str, path to the JSON file.\n",
        "\n",
        "    Returns:\n",
        "    - chain_iptm_data: 2D NumPy array of chain iptm values.\n",
        "    - metrics: Dictionary containing the values for \"fraction_disordered\", \"has_clash\",\n",
        "               \"iptm\", \"num_recycles\", \"ptm\", and \"ranking_score\".\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(json_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        chain_iptm_data = np.array(data['chain_iptm'])\n",
        "        chain_ptm_data = np.array(data['chain_ptm'])\n",
        "\n",
        "        return chain_iptm_data, chain_ptm_data\n",
        "    except (FileNotFoundError, json.JSONDecodeError, KeyError) as e:\n",
        "        print(f\"Error loading JSON file: {e}\")\n",
        "        return None, None\n",
        "\n",
        "\n",
        "\n",
        "def plot_boxplot(data, title, labels, output_dir, filename):\n",
        "    \"\"\"\n",
        "    Create a boxplot of the aggregated data and save it.\n",
        "\n",
        "    Parameters:\n",
        "    - data: List of 1D NumPy arrays containing the chain data (either IPTM or PTM).\n",
        "    - title: Title of the boxplot.\n",
        "    - labels: List of labels corresponding to the data.\n",
        "    - output_dir: str, directory to save the plot.\n",
        "    - filename: Name of the file to save the plot as.\n",
        "    \"\"\"\n",
        "    # Create a figure for the boxplot\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "    num_chains = len(labels)\n",
        "\n",
        "    # Choose a colormap with enough colors\n",
        "    if num_chains <= 10:\n",
        "        color_palette = colormaps[\"tab10\"]  # A colormap with 10 colors\n",
        "    elif num_chains <= 20:\n",
        "        color_palette = colormaps[\"tab20\"] # A colormap with 20 colors\n",
        "    else:\n",
        "        color_palette = colormaps[\"tab20c\" ] # A colormap with a larger range of colors\n",
        "\n",
        "        # Generate colors for each chain\n",
        "    colors = [color_palette(i / num_chains) for i in range(num_chains)]\n",
        "\n",
        "\n",
        "    # Plot the boxplot\n",
        "    sns.boxplot(data=data, ax=ax, palette=colors)\n",
        "    sns.stripplot(data=data, size=4, color=\".3\")\n",
        "\n",
        "    # Set the labels and title\n",
        "    ax.set_xticklabels(labels)\n",
        "    ax.set_title(title)\n",
        "    ax.set_ylabel('Values')\n",
        "    ax.spines[[\"right\", \"top\"]].set_visible(False)\n",
        "\n",
        "    # Save the plot\n",
        "    output_file = os.path.join(output_dir, filename)\n",
        "    plt.savefig(output_file)\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def process_folder(folder_path, output_dir):\n",
        "    \"\"\"\n",
        "    Process all JSON files in the folder matching the pattern *summary_confidences_*.json,\n",
        "    aggregate data, and plot a boxplot for each dataset (chain_iptm_data and chain_ptm_data).\n",
        "\n",
        "    Parameters:\n",
        "    - folder_path: str, path to the folder containing JSON files.\n",
        "    - output_dir: str, path to save the plots.\n",
        "    \"\"\"\n",
        "    json_files = glob.glob(f\"{folder_path}/*summary_confidences_*.json\")\n",
        "    if not json_files:\n",
        "        print(f\"No matching JSON files found in folder: {folder_path}\")\n",
        "        return\n",
        "\n",
        "    # Create the output directory if it doesn't exist\n",
        "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Initialize lists to store data for each chain (per chain, aggregated across files)\n",
        "    aggregated_chain_iptm_data = []\n",
        "    aggregated_chain_ptm_data = []\n",
        "    all_labels = []\n",
        "\n",
        "    # Iterate over each JSON file\n",
        "    for json_file in json_files:\n",
        "        json_file_name = Path(json_file).stem\n",
        "\n",
        "        chain_iptm_data, chain_ptm_data = load_data_from_json(json_file)\n",
        "\n",
        "        if chain_iptm_data is not None and chain_ptm_data is not None:\n",
        "            # Create labels for the chains (using the length of the data)\n",
        "            labels = [chr(i) for i in range(65, 65 + len(chain_iptm_data))]  # Corrected for 1D data\n",
        "            all_labels = labels  # Assuming labels are consistent across all files\n",
        "\n",
        "            # Append each chain's data across all files (aggregating by chain)\n",
        "            if not aggregated_chain_iptm_data:\n",
        "                # Initialize the aggregated lists with empty lists for each chain\n",
        "                aggregated_chain_iptm_data = [[] for _ in range(len(chain_iptm_data))]\n",
        "                aggregated_chain_ptm_data = [[] for _ in range(len(chain_ptm_data))]\n",
        "\n",
        "            # Aggregate the data for each chain (column-wise)\n",
        "            for i in range(len(chain_iptm_data)):\n",
        "                aggregated_chain_iptm_data[i].append(chain_iptm_data[i])\n",
        "                aggregated_chain_ptm_data[i].append(chain_ptm_data[i])\n",
        "        else:\n",
        "            print(f\"Skipping file due to error: {json_file}\")\n",
        "\n",
        "    if aggregated_chain_iptm_data and aggregated_chain_ptm_data:\n",
        "        # Now plot separate boxplots for chain_iptm_data and chain_ptm_data\n",
        "        plot_boxplot(aggregated_chain_iptm_data, 'Chain IPTM Data', all_labels, output_dir, 'chain_iptm_data.png')\n",
        "        plot_boxplot(aggregated_chain_ptm_data, 'Chain PTM Data', all_labels, output_dir, 'chain_ptm_data.png')\n",
        "        print(\"Plots saved\")\n",
        "    else:\n",
        "        print(\"No valid data to plot.\")\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    json_file_path = \"/content/unzipped_files\"  # Replace with your JSON file path\n",
        "    output_dir = \"/content/outputs/\"   # Replace with your desired PDF file path\n",
        "\n",
        "    # Process all matching JSON files in the folder\n",
        "    process_folder(json_file_path, output_dir)\n",
        "\n",
        "\n",
        "main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "5K_lOCbrM_XI",
        "outputId": "2680cf56-0360-4945-c30d-d9ab1894408b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plots saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown  Run this cell to generate summary Plots (*_summary.png)\n",
        "\n",
        "#@markdown  These plots provide an overview of the predicted structure quality and inter-chain interactions.\n",
        "\n",
        "#@markdown * chain_pair_pae_min: Helps identify interacting chains. Lower values suggest a higher likelihood of interaction.\n",
        "#@markdown * chain_pair_iptm: Measures the confidence in predicted interactions between pairs of chains. Useful for evaluating the accuracy of specific interfaces (e.g., antibody-antigen binding).\n",
        "#@markdown * chain_ptm: Estimates the accuracy of individual chain predictions.\n",
        "#@markdown * chain_iptm: Assesses the average confidence in the interfaces between a specific chain and all other chains. Useful for analyzing ligand binding.\n",
        "\n",
        "\n",
        "def load_data_from_json(json_path):\n",
        "    \"\"\"\n",
        "    Load chain iptm data and other metrics from a JSON file.\n",
        "\n",
        "    Parameters:\n",
        "    - json_path: str, path to the JSON file.\n",
        "\n",
        "    Returns:\n",
        "    - chain_iptm_data: 2D NumPy array of chain iptm values.\n",
        "    - metrics: Dictionary containing the values for \"fraction_disordered\", \"has_clash\",\n",
        "               \"iptm\", \"num_recycles\", \"ptm\", and \"ranking_score\".\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(json_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        chain__pair_iptm_data = np.array(data['chain_pair_iptm'])\n",
        "        chain_pair_pae_min_data = np.array(data['chain_pair_pae_min'])\n",
        "        chain_iptm_data = np.array(data['chain_iptm'])\n",
        "        chain_ptm_data = np.array(data['chain_ptm'])\n",
        "\n",
        "        metrics = {\n",
        "            \"fraction_disordered\": data.get(\"fraction_disordered\"),\n",
        "            \"has_clash\": data.get(\"has_clash\"),\n",
        "            \"iptm\": data.get(\"iptm\"),\n",
        "            \"num_recycles\": data.get(\"num_recycles\"),\n",
        "            \"ptm\": data.get(\"ptm\"),\n",
        "            \"ranking_score\": data.get(\"ranking_score\")\n",
        "        }\n",
        "        return chain__pair_iptm_data, metrics, chain_pair_pae_min_data, chain_iptm_data, chain_ptm_data\n",
        "    except (FileNotFoundError, json.JSONDecodeError, KeyError) as e:\n",
        "        print(f\"Error loading JSON file: {e}\")\n",
        "        return None, None\n",
        "\n",
        "\n",
        "\n",
        "def plot_heatmap_with_table(data1, data2, data3, data4, labels, metrics, output_dir, json_file_name):\n",
        "    \"\"\"\n",
        "    Plot two heatmaps and two linear heatmaps with different plot heights.\n",
        "\n",
        "    Parameters:\n",
        "    - data1: 2D NumPy array for the first heatmap.\n",
        "    - data2: 2D NumPy array for the second heatmap.\n",
        "    - data3: 1D NumPy array for the third heatmap (horizontal).\n",
        "    - data4: 1D NumPy array for the fourth heatmap (horizontal).\n",
        "    - labels: List of labels for the heatmap axes.\n",
        "    - metrics: Dictionary containing additional metrics.\n",
        "    \"\"\"\n",
        "    # Create a figure with GridSpec\n",
        "    fig = plt.figure(figsize=(26, 18))\n",
        "    spec = GridSpec(4, 4, figure=fig, height_ratios=[2, 0.2, 0.2, 0.4])  # Adjusted for more space below\n",
        "\n",
        "    # Define axes\n",
        "    ax1 = fig.add_subplot(spec[0, 0:2])  # Top-left: spans 2 columns\n",
        "    ax2 = fig.add_subplot(spec[0, 2:4])  # Top-right: spans 2 columns\n",
        "    ax3 = fig.add_subplot(spec[1, 1:3])  # Bottom-left: smaller and centered\n",
        "    ax4 = fig.add_subplot(spec[2, 1:3])  # Bottom-right: smaller and centered\n",
        "    ax_table = fig.add_subplot(spec[3, 1:3])  # Space for the table below\n",
        "\n",
        "    # Plot first heatmap\n",
        "    sns.heatmap(data1, annot=True, cmap=\"Blues\", xticklabels=labels, yticklabels=labels,\n",
        "                cbar_kws={'label': 'iptm Score'}, vmin=0, vmax=1, ax=ax1)\n",
        "    ax1.set_title(\"Chain Pair IPTM Heatmap\")\n",
        "    ax1.set_xlabel(\"Chain Labels\")\n",
        "    ax1.set_ylabel(\"Chain Labels\")\n",
        "    ax1.xaxis.set_ticks_position('top')\n",
        "\n",
        "    # Plot second heatmap\n",
        "    sns.heatmap(data2, annot=True, cmap=\"Greens_r\", xticklabels=labels, yticklabels=labels,\n",
        "                cbar_kws={'label': 'PAE Score'}, vmin=0, vmax=32, ax=ax2)\n",
        "    ax2.set_title(\"Chain Pair PAE Heatmap\")\n",
        "    ax2.set_xlabel(\"Chain Labels\")\n",
        "    ax2.set_ylabel(\"Chain Labels\")\n",
        "    ax2.xaxis.set_ticks_position('top')\n",
        "\n",
        "    # Plot third heatmap\n",
        "    im = sns.heatmap(np.array(data3).reshape(1, -1), annot=True, cmap=\"coolwarm_r\", xticklabels=labels, cbar = False,\n",
        "                     cbar_kws={'label': 'Chain iptm'}, vmin=0, vmax=1, ax=ax3)\n",
        "    ax3.set_title(\"Heatmap of chain iptm\")\n",
        "    ax3.set_yticks([])  # Remove y-axis ticks for linear data\n",
        "\n",
        "    # Plot fourth heatmap\n",
        "    sns.heatmap(np.array(data4).reshape(1, -1), annot=True, cmap=\"coolwarm_r\", xticklabels=labels, cbar = False,\n",
        "                cbar_kws={'label': 'Chain ptm'}, vmin=0, vmax=1, ax=ax4)\n",
        "    ax4.set_title(\"Heatmap of chain ptm\")\n",
        "    ax4.set_yticks([])  # Remove y-axis ticks for linear data\n",
        "\n",
        "    # Colorbar for third and fourth heatmaps\n",
        "    mappable = im.get_children()[0]\n",
        "    plt.colorbar(mappable, ax=[ax3, ax4], orientation='horizontal')\n",
        "\n",
        "    # Add table\n",
        "    ax_table.axis('off')  # Turn off the axis for the table\n",
        "    table = Table(ax_table, bbox=[0, 0, 1, 1])  # Adjust bbox to fit the table within the axis\n",
        "\n",
        "    table.auto_set_column_width([0.5, 0.5])\n",
        "    # Display additional metrics as a table\n",
        "    # Add rows to the table\n",
        "    for i, (key, value) in enumerate(metrics.items()):\n",
        "        table.add_cell(i, 0, 0.2, 0.3, text=key, loc='center', edgecolor='black', facecolor='lightgray')\n",
        "        table.add_cell(i, 1, 0.2, 0.3, text=value, loc='center', edgecolor='black')\n",
        "\n",
        "    # Add header row\n",
        "    table.add_cell(-1, 0, 0.2, 0.3, text=\"Metric\", loc='center', edgecolor='black', facecolor='lightblue')\n",
        "    table.add_cell(-1, 1, 0.2, 0.3, text=\"Value\", loc='center', edgecolor='black', facecolor='lightblue')\n",
        "\n",
        "    ax_table.add_table(table)\n",
        "\n",
        "        # Save the plot\n",
        "    output_file = Path(output_dir) / f\"{json_file_name}_summary.png\"\n",
        "    plt.savefig(output_file, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"Combined plot saved to {output_file}\")\n",
        "\n",
        "\n",
        "def process_folder(folder_path, output_dir):\n",
        "    \"\"\"\n",
        "    Process all JSON files in the folder matching the pattern *summary_confidences_*.json.\n",
        "\n",
        "    Parameters:\n",
        "    - folder_path: str, path to the folder containing JSON files.\n",
        "    - output_dir: str, path to save the plots.\n",
        "    \"\"\"\n",
        "    json_files = glob.glob(f\"{folder_path}/*summary_confidences_*.json\")\n",
        "    if not json_files:\n",
        "        print(f\"No matching JSON files found in folder: {folder_path}\")\n",
        "        return\n",
        "\n",
        "    # Create the output directory if it doesn't exist\n",
        "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    for json_file in json_files:\n",
        "        json_file_name = Path(json_file).stem\n",
        "        print(f\"Processing file: {json_file}\")\n",
        "        chain__pair_iptm_data, metrics, chain_pair_pae_min_data, chain_iptm_data, chain_ptm_data = load_data_from_json(json_file)\n",
        "\n",
        "        if chain__pair_iptm_data is not None:\n",
        "            # Create labels for the columns (alphabetical order starting with 'A')\n",
        "            labels = [chr(i) for i in range(65, 65 + chain__pair_iptm_data.shape[1])]\n",
        "\n",
        "            Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
        "            fig, axes = plt.subplots(2, 2, figsize=(24, 16))\n",
        "            (ax1, ax2), (ax3, ax4) = axes\n",
        "\n",
        "            plot_heatmap_with_table(chain__pair_iptm_data, chain_pair_pae_min_data, chain_iptm_data,chain_ptm_data, labels, metrics, output_dir, json_file_name)\n",
        "\n",
        "        else:\n",
        "            print(f\"Skipping file due to error: {json_file}\")\n",
        "\n",
        "plt.ioff()\n",
        "\n",
        "def main():\n",
        "    json_file_path = \"/content/unzipped_files\"  # Replace with your JSON file path\n",
        "    output_dir = \"/content/outputs/\"   # Replace with your desired PDF file path\n",
        "\n",
        "    # Process all matching JSON files in the folder\n",
        "    process_folder(json_file_path, output_dir)\n",
        "\n",
        "\n",
        "main()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "xbbSzSlkPO83",
        "outputId": "a2890e23-7d79-41bd-d6d1-36fcc0e4b366"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file: /content/unzipped_files/fold_protein_dna_kat6a_summary_confidences_2.json\n",
            "Combined plot saved to /content/outputs/fold_protein_dna_kat6a_summary_confidences_2_summary.png\n",
            "Processing file: /content/unzipped_files/fold_protein_dna_kat6a_summary_confidences_0.json\n",
            "Combined plot saved to /content/outputs/fold_protein_dna_kat6a_summary_confidences_0_summary.png\n",
            "Processing file: /content/unzipped_files/fold_protein_dna_kat6a_summary_confidences_3.json\n",
            "Combined plot saved to /content/outputs/fold_protein_dna_kat6a_summary_confidences_3_summary.png\n",
            "Processing file: /content/unzipped_files/fold_protein_dna_kat6a_summary_confidences_1.json\n",
            "Combined plot saved to /content/outputs/fold_protein_dna_kat6a_summary_confidences_1_summary.png\n",
            "Processing file: /content/unzipped_files/fold_protein_dna_kat6a_summary_confidences_4.json\n",
            "Combined plot saved to /content/outputs/fold_protein_dna_kat6a_summary_confidences_4_summary.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown  Run this cell to generate report\n",
        "\n",
        "#@markdown * Report Data (report.df), provides essential information about the protein sequence and chains, including chain ID, type, and length.\n",
        "\n",
        "#@markdown To make it easier for you, select this cell once, go to the Runtime > Run cell and below or do Ctr+F10 (Windows), Command+F10 (Mac). This will run this cell and the onces below sequentially.\n",
        "\n",
        "def generate_alphafold_pdf_report(folder_path, output_pdf_path):\n",
        "    # Load the JSON file\n",
        "    json_files = glob.glob(f\"{folder_path}/*job_request.json\")\n",
        "    if not json_files:\n",
        "        print(f\"No matching JSON file found in folder: {folder_path}\")\n",
        "        return\n",
        "\n",
        "    json_file = json_files[0]  # Select the first file from the list\n",
        "\n",
        "    with open(json_file, 'r') as file:\n",
        "      data = json.load(file)\n",
        "\n",
        "    # Function to generate chain labels based on the count starting from the given index\n",
        "    def generate_chain_labels(start_index, count):\n",
        "        \"\"\"Generate chain labels based on the count starting from the given index.\"\"\"\n",
        "        labels = []\n",
        "        alphabet = string.ascii_uppercase\n",
        "        for i in range(count):\n",
        "            label = ''\n",
        "            n = start_index + i\n",
        "            while n >= 0:\n",
        "                label = alphabet[n % 26] + label\n",
        "                n = n // 26 - 1\n",
        "            labels.append(label)\n",
        "        return labels\n",
        "\n",
        "    # Assign labels and add to each sequence\n",
        "    last_used_index = 0\n",
        "    for entry in data:\n",
        "        for sequence in entry[\"sequences\"]:\n",
        "            if \"proteinChain\" in sequence:\n",
        "                seq = sequence[\"proteinChain\"]\n",
        "                chain_labels = generate_chain_labels(last_used_index, seq['count'])\n",
        "                # Assign the labels to the sequence\n",
        "                sequence[\"chainLabels\"] = chain_labels\n",
        "                last_used_index += seq['count']\n",
        "            elif \"dnaSequence\" in sequence:\n",
        "                seq = sequence[\"dnaSequence\"]\n",
        "                chain_labels = generate_chain_labels(last_used_index, seq['count'])\n",
        "                # Assign the labels to the sequence\n",
        "                sequence[\"chainLabels\"] = chain_labels\n",
        "                last_used_index += seq['count']\n",
        "\n",
        "    # Initialize the PDF canvas\n",
        "    pdf = canvas.Canvas(output_pdf_path, pagesize=letter)\n",
        "    width, height = letter\n",
        "\n",
        "    # Font settings\n",
        "    pdf.setFont(\"Helvetica\", 10)\n",
        "    margin = 50\n",
        "    line_spacing = 14\n",
        "    y_position = height - margin  # Start near the top of the page\n",
        "\n",
        "    # Maximum width for text wrapping\n",
        "    max_line_length = 60  # Maximum number of characters per line for sequences\n",
        "\n",
        "    def wrap_long_text(text, max_length):\n",
        "        \"\"\"Split text into lines of specified max length.\"\"\"\n",
        "        return [text[i:i + max_length] for i in range(0, len(text), max_length)]\n",
        "\n",
        "    for entry in data:\n",
        "        # Entry title\n",
        "        pdf.setFont(\"Helvetica-Bold\", 12)\n",
        "        pdf.drawString(margin, y_position, f\"{entry['name']}\")\n",
        "        y_position -= line_spacing\n",
        "\n",
        "        pdf.setFont(\"Helvetica\", 10)\n",
        "\n",
        "        # Print model seeds\n",
        "        model_seeds = \"Model Seeds: \" + \", \".join(entry[\"modelSeeds\"])\n",
        "        pdf.drawString(margin, y_position, model_seeds)\n",
        "        y_position -= line_spacing\n",
        "\n",
        "        # Print sequence details\n",
        "        pdf.drawString(margin, y_position, \"Sequences:\")\n",
        "        y_position -= line_spacing\n",
        "\n",
        "        for sequence in entry[\"sequences\"]:\n",
        "            # Print chain labels and sequence details\n",
        "            chain_labels = \", \".join(sequence[\"chainLabels\"])\n",
        "            if \"proteinChain\" in sequence:\n",
        "                seq = sequence[\"proteinChain\"]\n",
        "                y_position -= line_spacing\n",
        "                header = f\"Protein Sequence Chains {chain_labels} (Count = {seq['count']}, Length = {len(seq['sequence'])}):\"\n",
        "                pdf.drawString(margin + 20, y_position, header)\n",
        "                y_position -= line_spacing\n",
        "\n",
        "                # Wrap and print the sequence\n",
        "                sequence_lines = wrap_long_text(seq[\"sequence\"], max_line_length)\n",
        "                for line in sequence_lines:\n",
        "                    pdf.drawString(margin + 40, y_position, line)\n",
        "                    y_position -= line_spacing\n",
        "\n",
        "            elif \"dnaSequence\" in sequence:\n",
        "                seq = sequence[\"dnaSequence\"]\n",
        "                y_position -= line_spacing\n",
        "                header = f\"DNA Sequence Chains {chain_labels} (Count = {seq['count']}, Length = {len(seq['sequence'])}):\"\n",
        "                pdf.drawString(margin + 20, y_position, header)\n",
        "                y_position -= line_spacing\n",
        "\n",
        "                # Wrap and print the sequence\n",
        "                sequence_lines = wrap_long_text(seq[\"sequence\"], max_line_length)\n",
        "                for line in sequence_lines:\n",
        "                    pdf.drawString(margin + 40, y_position, line)\n",
        "                    y_position -= line_spacing\n",
        "\n",
        "            # Check if a new page is needed\n",
        "            if y_position < margin:\n",
        "                pdf.showPage()\n",
        "                pdf.setFont(\"Helvetica\", 10)\n",
        "                y_position = height - margin\n",
        "\n",
        "        # Add space between entries\n",
        "        y_position -= line_spacing\n",
        "        if y_position < margin:\n",
        "            pdf.showPage()\n",
        "            pdf.setFont(\"Helvetica\", 10)\n",
        "            y_position = height - margin\n",
        "\n",
        "    # Save the PDF\n",
        "    pdf.save()\n",
        "    print(f\"PDF report generated and saved to {output_pdf_path}\")\n",
        "\n",
        "#Run\n",
        "json_file_path = \"/content/unzipped_files\"  # Replace with your JSON file path\n",
        "output_pdf_path = \"/content/outputs/alphafold3_report.pdf\"   # Replace with your desired PDF file path\n",
        "generate_alphafold_pdf_report(json_file_path, output_pdf_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "CnkJwz7QIgey",
        "outputId": "c1de02a8-eae1-4155-81e5-804bfbdeb15f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDF report generated and saved to /content/outputs/alphafold3_report.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown  Run this cell to download all plots in a zip file\n",
        "import os\n",
        "import zipfile\n",
        "from google.colab import files  # Ensure you're importing this\n",
        "import shutil\n",
        "\n",
        "# Define the zip filename and output directory\n",
        "zip_filename = \"af_server_reports.zip\"\n",
        "output = \"/content/outputs\"\n",
        "\n",
        "# Zip the extracted files\n",
        "with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "    for root, dirs, docs in os.walk(output):\n",
        "        for file in docs:\n",
        "            file_path = os.path.join(root, file)\n",
        "            # Write file to the zip archive, maintaining directory structure\n",
        "            zipf.write(file_path, os.path.relpath(file_path, output))\n",
        "            os.remove(file_path)\n",
        "\n",
        "# Notify that the zip file has been created\n",
        "print(f\"Created zip archive: {zip_filename}\")\n",
        "\n",
        "# Download the zip file\n",
        "files.download(zip_filename)  # This should work now"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "WJbk3aLBVpSz",
        "outputId": "30160942-c27a-4466-e86a-b6010ae362cd",
        "cellView": "form"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created zip archive: af_server_reports.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_bea0a1d6-bae6-44e8-b79b-96ba09c95e7c\", \"af_server_reports.zip\", 12394392)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Understanding AlphaFold confidence metrics\n",
        "\n",
        "AlphaFold provides several metrics to help you assess the reliability of its predictions. These metrics are calculated for \"tokens\", which encompass amino acids, small molecules, and chemical modifications, enabling AlphaFold to handle diverse macromolecular complexes.\n",
        "\n",
        "-  **pLDDT (Predicted Local Distance Difference Test)**\n",
        "This score estimates the confidence in the local structure around each atom. It ranges from 0-100, with higher scores indicating greater confidence.\n",
        "  - pLDDT > 90: High confidence\n",
        "  - pLDDT < 50: Likely incorrect.\n",
        "\n",
        "\n",
        "* **PAE (Predicted Aligned Error)**: This score measures the expected error in the relative positions of two tokens in the predicted structure. Higher PAE values indicate lower confidence. Low PAE between tokens from different molecules suggests potential interaction.\n",
        "\n",
        "  - PAE is calculated slightly differently for different types of molecule. For proteins and nucleic acids, PAE is measured relative to frames constructed from the backbone atoms of those macromolecules. For small entities like ions, ligands and chemical modifications, a frame is constructed for each atom from its closest neighbours, using a molecule in a reference conformation.\n",
        "\n",
        "* **pTM (Predicted TM-score)**: This score assesses the accuracy of the overall structure of the complex or individual chains. *It is less useful for small structures or short chains*. This is because the TM score is very strict for smaller molecules, so pTM assigns values below 0.05 when fewer than 20 tokens are involved. For these cases, PAE and/or pLDDT may be more indicative of prediction accuracy.\n",
        "\n",
        "* **ipTM (Interface Predicted TM-score)**: This score measures the precision of predictions of individual entities and their interactions within the complex. An ipTM score above 0.8 indicates a high-confidence interaction.\n",
        "<br>\n",
        "\n",
        "**Important Considerations**\n",
        "\n",
        "- Confidence scores can be affected by the presence or absence of non-polymer context (e.g., ions, ligands).\n",
        "- Disordered regions can lower pTM and ipTM scores, so it's important to examine the PAE plot for potential interactions even if these scores are low."
      ],
      "metadata": {
        "id": "g3j7eMcc7tIm"
      }
    }
  ]
}